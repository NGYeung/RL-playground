{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import random\n",
    "import string\n",
    "import secrets\n",
    "import time\n",
    "import re\n",
    "import collections\n",
    "\n",
    "try:\n",
    "    from urllib.parse import parse_qs, urlencode, urlparse\n",
    "except ImportError:\n",
    "    from urlparse import parse_qs, urlparse\n",
    "    from urllib import urlencode\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Text, MultiDiscrete, Discrete, MultiBinary, Tuple\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import logging\n",
    "from collections import namedtuple, Counter, defaultdict\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.cuda import init\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "import time\n",
    "import logging\n",
    "\n",
    "#https://huggingface.co/docs/transformers/en/model_doc/decision_transformer\n",
    "from transformers import DecisionTransformerConfig, DecisionTransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('root')\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = open(\"words_250000_train.txt\", 'r').readlines()\n",
    "word_list = [word.strip() for word in train_dict]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_word_dictionary(words):\n",
    "    \"\"\"\n",
    "    This function creates a dictionary where keys are word lengths and values are lists of words with that length.\n",
    "    \"\"\"\n",
    "    n_word_dictionary = defaultdict(list)\n",
    "\n",
    "    for word in words:\n",
    "        length = len(word)\n",
    "        n_word_dictionary[length].append(word)\n",
    "\n",
    "    return dict(n_word_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_dict = create_n_word_dictionary(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vowel vs. consonants\n",
    "def count_aeiou(dictionary):\n",
    "    b05 = 0\n",
    "    b = [0 for i in range(len(dictionary))]\n",
    "    b045 = 0\n",
    "    b055 = 0\n",
    "    k =11\n",
    "    for i in range(len(dictionary)):\n",
    "        b[i] = sum([1 if ltr in 'aeiou' else 0 for ltr in dictionary[i]])/len(dictionary[i])\n",
    "        if b[i] < 0.55 and len(dictionary[i]) == k:\n",
    "            b05 += 1\n",
    "        if b[i] < 0.45 and len(dictionary[i]) == k:\n",
    "            b045 += 1\n",
    "    print(b05/len(word_count_dict[k]),b045/len(word_count_dict[k]))\n",
    "            \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9959624330729395 0.6033529360133415\n"
     ]
    }
   ],
   "source": [
    "bar = count_aeiou(word_list)\n",
    "# the 0.45 rule doesn't work for len <= 4 and >= 12\n",
    "# 0.55 is the better threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 28 artists>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# word length distribution\n",
    "lengths = list(word_count_dict.keys())\n",
    "frequencies = [len(words) for words in word_count_dict.values()]\n",
    "\n",
    "plt.bar(lengths, frequencies, color='skyblue', edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.2490e+03, 2.0000e+00, 6.8100e+02, 1.7410e+03, 6.7780e+03,\n",
       "        3.2538e+04, 3.5853e+04, 3.6370e+04, 6.0189e+04, 1.2807e+04,\n",
       "        2.8992e+04, 7.8220e+03, 7.7600e+02, 1.1180e+03, 1.0800e+02,\n",
       "        1.8300e+02, 5.4000e+01, 1.0000e+00, 0.0000e+00]),\n",
       " array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
       "        0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95]),\n",
       " <BarContainer object of 19 artists>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.arange(0.0, 1.0, 0.05)\n",
    "plt.hist(x = bar, bins = bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_ngrams(word, n):\n",
    "    ngrams = [word[i:i+n] for i in range(len(word)-n+1)]\n",
    "    return ngrams\n",
    "\n",
    "def count_ngrams(wordlist, n):\n",
    "\n",
    "    all_ngrams = []\n",
    "    for word in wordlist:\n",
    "        ngrams = letter_ngrams(word, n)\n",
    "        all_ngrams.extend(ngrams)\n",
    "    return Counter(all_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Config:\n",
    "    \"\"\" User config class \"\"\"\n",
    "    def __init__(self, path: str=None): \n",
    "        \n",
    "        self.model = 'lstm' #or 'transformer'\n",
    "        self.lossfn = 'mse' #or 'mse'\n",
    "        self.batch_size = 128\n",
    "        self.learning_rate = 1e-4\n",
    "        self.num_episodes = 100000\n",
    "        self.mem_capacity = 10000\n",
    "        self.train_steps = 2000000\n",
    "        self.warmup = 15\n",
    "        self.gamma = 0.998 #for the learning rate\n",
    "        \n",
    "        #for exploit vs explore\n",
    "        self.starteps = 0.8\n",
    "        self.endeps = 0.05\n",
    "        self.decay_eps = 200\n",
    "        \n",
    "        self.target_update_freq = 1000\n",
    "        self.save_freq = 1000\n",
    "        self.save_file_name = 'train_new.pth'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    ''' Also for training.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save aone instance of transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Randomly sample a batch of transitions.\"\"\"\n",
    "        return rnd.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class n_gram():\n",
    "    '''\n",
    "    Classic statistic method in case for the love of God NN isn't the best fit.\n",
    "    Also can be used to help with training the RL agent.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    def __init__(self, dictionary, list_to_exclude=[], trimlength=-1):\n",
    "\n",
    "        if trimlength == -1:\n",
    "            pass\n",
    "        else:\n",
    "            new_dict = []\n",
    "            for word in dictionary:\n",
    "                if len(word) == trimlength:\n",
    "                    new_dict.append(word)\n",
    "            dictionary = new_dict\n",
    "        \n",
    "        self.full_dict = dictionary #give me a list\n",
    "        self.dict_clean_up(list_to_exclude)\n",
    "        self.make_grams()\n",
    "        \n",
    "\n",
    "    def dict_clean_up(self, list_to_exclude):\n",
    "        '''\n",
    "        input = a list of letters\n",
    "        re-create everything excluding the letter that we don't want.\n",
    "        '''\n",
    "        full = self.full_dict\n",
    "        new_dict = []\n",
    "        for word in full:\n",
    "            logit = sum([1 if l in word else 0 for l in list_to_exclude])\n",
    "            if logit == 0:\n",
    "                new_dict.append(word)\n",
    "                \n",
    "        self.full_dict = new_dict\n",
    "                \n",
    "    \n",
    "    def make_grams(self):\n",
    "\n",
    "        self.unigram = count_ngrams(self.full_dict, 1)\n",
    "        self.bigram = count_ngrams(self.full_dict, 2)\n",
    "        self.trigram = count_ngrams(self.full_dict, 3)\n",
    "        self.quadgram = count_ngrams(self.full_dict, 4)\n",
    "        self.pentagram = count_ngrams(self.full_dict, 5)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    def get_slice(self, word_state, slice_len):\n",
    "        '''\n",
    "        get the pattern around the blank words\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        slice = []\n",
    "        count = 0\n",
    "        for k in word_state:\n",
    "            if k == -1:\n",
    "                break       \n",
    "            count += 1\n",
    "        '''\n",
    "        count = len(word_state)\n",
    "        slice = []\n",
    "\n",
    "        \n",
    "        for i in range(count-slice_len):\n",
    "    \n",
    "            if 26 in word_state[i:i+slice_len]:\n",
    "                s = word_state[i:i+slice_len]\n",
    "                st = ''\n",
    "                flag = 0\n",
    "                eq_ = sum([1 if n == 26 else 0 for n in s])\n",
    "                if eq_ == 1:\n",
    "                    for n in s:\n",
    "                        if n == 26:\n",
    "                            st += '.'\n",
    "                        else:\n",
    "                            st += chr(n+ord('a'))\n",
    "                if st != '':\n",
    "                    slice.append(st)\n",
    "                \n",
    "        return slice\n",
    "\n",
    "    \n",
    "    def ngram_probability(self, word_state, weight = [1/5, 2/5, 2/5, 1/5, 1/5 ]): \n",
    "        # create 1-5 gram\n",
    "\n",
    "\n",
    "        # 1\n",
    "        uni_p = [0 for i in range(26)]\n",
    "        \n",
    "        for letter, freq in self.unigram.items():\n",
    "   \n",
    "            uni_p[ord(letter)-ord('a')] = freq\n",
    "        uni_p = np.array(uni_p)/(sum(uni_p)+1e-9)\n",
    "\n",
    "        # 2\n",
    "        bi_p = [0 for i in range(26)]\n",
    "        slice = self.get_slice(word_state, 2)\n",
    "        matches = {}\n",
    "        compiled_patterns = [re.compile(pattern) for pattern in slice]\n",
    "        for pattern in compiled_patterns:\n",
    "            for gram, count in self.bigram.items():\n",
    "                if pattern.match(''.join(gram)):\n",
    "                    matches[gram] = count\n",
    "                    \n",
    "        for keys in matches:\n",
    "            for i in 'abcdeklmnfghijopqrstuvwxyz':\n",
    "                if i in keys:\n",
    "                    bi_p[ord(i)-ord('a')] += matches[keys]\n",
    "        bi_p = np.array(bi_p)/(sum(bi_p) + 1e-9)\n",
    "        #print(matches)\n",
    "\n",
    "        # 3\n",
    "        tri_p = [0 for i in range(26)]\n",
    "        slice = self.get_slice(word_state, 3)\n",
    "        matches = {}\n",
    "        compiled_patterns = [re.compile(pattern) for pattern in slice]\n",
    "        for pattern in compiled_patterns:\n",
    "            for gram, count in self.trigram.items():\n",
    "                if pattern.match(''.join(gram)):\n",
    "                    matches[gram] = count\n",
    "        #print(matches)\n",
    "        for keys in matches:\n",
    "            for i in 'abcdeklmnfghijopqrstuvwxyz':\n",
    "                if i in keys:\n",
    "                    tri_p[ord(i)-ord('a')] += matches[keys]\n",
    "        tri_p = np.array(tri_p)/(sum(tri_p) + 1e-9)\n",
    "\n",
    "\n",
    "        # 4\n",
    "        quad_p = [0 for i in range(26)]\n",
    "        slice = self.get_slice(word_state, 4)\n",
    "        matches = {}\n",
    "        \n",
    "        compiled_patterns = [re.compile(pattern) for pattern in slice]\n",
    "        for pattern in compiled_patterns:\n",
    "            for gram, count in self.quadgram.items():\n",
    "                if pattern.match(''.join(gram)):\n",
    "                    matches[gram] = count\n",
    "        #print(matches)       \n",
    "        for keys in matches:\n",
    "            for i in 'abcdeklmnfghijopqrstuvwxyz':\n",
    "                if i in keys:\n",
    "                    quad_p[ord(i)-ord('a')] += matches[keys]\n",
    "        quad_p = np.array(quad_p)/(sum(quad_p) + 1e-9)\n",
    "\n",
    "        # 5\n",
    "        penta_p = [0 for i in range(26)]\n",
    "        slice = self.get_slice(word_state, 5)\n",
    "        matches = {}\n",
    "        \n",
    "        compiled_patterns = [re.compile(pattern) for pattern in slice]\n",
    "        for pattern in compiled_patterns:\n",
    "            for gram, count in self.pentagram.items():\n",
    "                if pattern.match(''.join(gram)):\n",
    "                    matches[gram] = count\n",
    "        #print(matches)       \n",
    "        for keys in matches:\n",
    "            for i in 'abcdeklmnfghijopqrstuvwxyz':\n",
    "                if i in keys:\n",
    "                    quad_p[ord(i)-ord('a')] += matches[keys]\n",
    "        penta_p = np.array(penta_p)/(sum(penta_p) + 1e-9)\n",
    "\n",
    "\n",
    "        probability = weight[0]*uni_p + weight[1]*bi_p + weight[2]*tri_p + weight[3]*quad_p + weight[4]*penta_p\n",
    "\n",
    "     \n",
    "        return probability\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size=27, action_size=26):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size+action_size+1, 32)\n",
    "        self.conv = nn.Conv1d(in_channels=1, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        self.lstm = nn.LSTM(3*32, 3*32,  batch_first=True)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc2 = nn.Linear(3*32, action_size)\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # Initialize fully connected layers using Xavier initialization\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            elif 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "       \n",
    "        x = self.conv (x.reshape(-1,1,32))\n",
    "\n",
    "        x, _ = self.lstm(x.reshape(-1,1,3*32))\n",
    "\n",
    "        x = self.fc2(x.squeeze(0))\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hangman_Env(gym.Env):\n",
    "    \"\"\"Custom Hangman game Environment that follows gym interface.\"\"\"\n",
    "    \n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \n",
    "    def __init__(self, dict_file = None, MaxLen = 27):\n",
    "        \"\"\"Initialize the hangman game environment. \"\"\"\n",
    "        \n",
    "        \n",
    "        super(Hangman_Env, self).__init__()\n",
    "       \n",
    "        self.action_space = Discrete(26)  # the alphabet a-z = ord(x)-ord('a')\n",
    "        \n",
    "        self.observation_space = Tuple((\n",
    "\t\t\tMultiDiscrete(np.array([27]*MaxLen)),  # The state space of strings  \n",
    "\t\t\tMultiBinary([2]*26),# Guessed letters a-z guessed 1 unguessed 0\n",
    "            Discrete(6 + 1) # attempt left = 0-6\n",
    "            )) \n",
    "        #Example\n",
    "        #observation 0: a___e = [0 26 26 26 4 0000000..]\n",
    "        #observation 1:  only a and e are guessed [1 0 0 0 1 0000]\n",
    "        #observation 2: 3 attemps are left [3]\n",
    "        \n",
    "        if dict_file is None:\n",
    "            self.dictionary = list('no training dictionary for this game')\n",
    "        else:\n",
    "            f = open(dict_file, 'r').readlines()\n",
    "            self.dictionary = [word.strip() for word in f]\n",
    "            self.dictionary = random.sample(self.dictionary, len(self.dictionary))\n",
    "        \n",
    "        self.curr_word = \"\"\n",
    "        self.unknown_word = []\n",
    "        self.guessed_letters = np.zeros(26, dtype=int)\n",
    "        self.attempts_left = 6\n",
    "        self.win = False\n",
    "        self.MaxLen = MaxLen\n",
    "            \n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, word_to_guess = None):\n",
    "        \"\"\"Reset the state of the environment to an initial state\"\"\"\n",
    "        # Choose a random word from the list\n",
    "        if word_to_guess == None:\n",
    "            self.curr_word = rnd.choice(self.dictionary) \n",
    "        else:\n",
    "            self.curr_word = word_to_guess\n",
    "        \n",
    "        self.unknown_word = ['_'] * len(self.curr_word)  # Hidden word representation\n",
    "        self.guessed_letters = [0] * 26  # Initialize as all unguessed\n",
    "        self.attempts_left = 6  # 6 guesses for each word\n",
    "        logger.info(\"Reset: new word! new round!\")\n",
    "        logger.info(\"Reset: New word is [\" + self.curr_word +\"]\")\n",
    "        \n",
    "        return self.get_observation()\n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "       assert self.action_space.contains(action), f\"Invalid Action: {action} is not in the action space\"\n",
    "       # Just to help with debugging\n",
    "       \n",
    "       done = False\n",
    "       reward = 0\n",
    "\n",
    "       # Convert action to character\n",
    "       char2guess = chr(action + ord('a'))\n",
    "\n",
    "       # If the character was already guessed, return current state with no reward\n",
    "       if self.guessed_letters[action] == 1:\n",
    "           return self.get_observation(), reward, done, {}\n",
    "\n",
    "       self.guessed_letters[action] = 1\n",
    "\n",
    "       if char2guess in self.curr_word:\n",
    "           # Correct guess\n",
    "           reward = 3\n",
    "           for idx, char in enumerate(self.curr_word):\n",
    "               if char == char2guess:\n",
    "                   self.unknown_word[idx] = char2guess\n",
    "           if '_' not in self.unknown_word:\n",
    "               done = True\n",
    "               reward = 10  # Extra reward for winning\n",
    "       else:\n",
    "           # Incorrect guess\n",
    "           self.attempts_left -= 1\n",
    "           if self.attempts_left == 0:\n",
    "               done = True\n",
    "               reward = -10  # Penalty for losing\n",
    "       \n",
    "        \n",
    "\n",
    "       return self.get_observation(), reward, done, {}\n",
    "    \n",
    "    def get_observation(self):\n",
    "        \n",
    "        unknown_word_logits = [26 if char == '_' else ord(char)-ord('a') for char in self.unknown_word]\n",
    "        padding = [-1]*(self.MaxLen-len(unknown_word_logits))\n",
    "        # 1 =  know 0 = unknown\n",
    "        return torch.tensor(unknown_word_logits+padding), torch.tensor(self.guessed_letters), self.attempts_left, {}\n",
    "    \n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        unknown_word_str = \" \".join(self.unknown_word)\n",
    "        guessed_letters_str = \", \".join([chr(i + ord('a')) for i, val in enumerate(self.guessed_letters) if val == 1])\n",
    "        print(f\"Word: {unknown_word_str}\")\n",
    "        print(f\"Guessed Letters: {guessed_letters_str}\")\n",
    "        print(f\"Attempts Left: {self.attempts_left}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class agent_hangman():\n",
    "    '''\n",
    "    so that I can play this thing locally.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        en = Hangman_Env(dict_file = \"words_250000_train.txt\")\n",
    "        self.config = Config() #alpha beta gamma batch_size\n",
    "        self.state_size = 27\n",
    "        self.action_size = 26\n",
    "        self.memory = ReplayMemory(self.config.mem_capacity)\n",
    "        self.step_count = 0\n",
    "        self.episode_durations = []\n",
    "        self.last_episode = 0\n",
    "        self.reward_in_episode = []\n",
    "\n",
    "\n",
    "        self.env = en\n",
    "        self.id = int(time.time())\n",
    "        \n",
    "        \n",
    "        #self.n_actions = self.env.action_space.n\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Use Double DQN and if it's an overshoot then switch back to usual dqn\n",
    "        if self.config.model == 'transformer':\n",
    "            self.transformerConfig = DecisionTransformerConfig( \n",
    "            state_dim = self.state_size, act_dim = self.action_size, hidden_size = 64, action_tanh = True, \n",
    "            vocab_size = 26, n_positions = 64, n_layer = 3, n_head = 4\n",
    "            ) \n",
    "            self.policy_net = DecisionTransformerModel(self.transformerConfig).to(self.device)\n",
    "            self.target_net = DecisionTransformerModel(self.transformerConfig).to(self.device)\n",
    "        \n",
    "        if self.config.model == 'lstm':\n",
    "            self.policy_net = DQN().to(self.device)\n",
    "            self.target_net = DQN().to(self.device)\n",
    "            \n",
    "        self.optimizer = optim.RMSprop(self.policy_net.parameters(),lr = 1e-4, alpha=0.99, eps=1e-8, weight_decay=1e-5)\n",
    "        self.scheduler = lr_scheduler.ExponentialLR(self.optimizer, self.config.gamma)\n",
    "        self.target_net.eval()\n",
    "        \n",
    "    def update_target_net(self):\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.target_net.eval()\n",
    "\n",
    "    \n",
    "    def eps_scheduler(self):\n",
    "        '''\n",
    "        Adaptively balance explore or exploit, using exponential decay. For training purposes\n",
    "        '''    \n",
    "        return self.config.endeps + (self.config.starteps - self.config.endeps)*math.exp(-1. * self.step_count / self.config.decay_eps/100)\n",
    "\n",
    "    \n",
    "    def do_vowel(self, state):\n",
    "        '''\n",
    "        function to decide whether to select a vowel.\n",
    "        '''\n",
    "        l = len(self.env.curr_word)\n",
    "        thres = l//2\n",
    "        vowel_idx = [0,4,8,14,20]\n",
    "        vowel_count = sum([1 if i in vowel_idx else 0 for i in state])\n",
    "        return vowel_count < thres\n",
    "        \n",
    "\n",
    "    def heuristic_action(self, state):\n",
    "        guessed = state[27:]\n",
    "\n",
    "        \n",
    "        select = rnd.choice([i for i in range(26)])\n",
    "        while guessed[select] == 1:\n",
    "            select = rnd.choice([i for i in range(26)])\n",
    "        return select\n",
    "        \n",
    "        '''\n",
    "        state = state[0:27]\n",
    "        if not self.do_vowel:\n",
    "            letter_frequencies = 'tsnhrdmwgvlfbkpxczjyq' #adjusted for training to leveral explore vs. exploit\n",
    "        else:\n",
    "            letter_frequencies = 'eitsanhurdmwgvlfbkopxczjyq'\n",
    "        \n",
    "        for idx in range(len(letter_frequencies)):\n",
    "            char = ord(letter_frequencies[idx]) - ord('a')\n",
    "            if self.env.guessed_letters[char] == 0:\n",
    "                return ord(letter_frequencies[idx]) - ord('a') '''\n",
    "\n",
    "\n",
    "    def correct_letter(self,state):\n",
    "        ''' The list of correct guess\n",
    "        '''\n",
    "        correct = []\n",
    "        state = state[0:27]\n",
    "        for i in state:\n",
    "            if 0<=i<=25:\n",
    "                correct.append(chr(i+ord('a')))\n",
    "        return correct\n",
    "\n",
    "   \n",
    "\n",
    "    def act_stat(self, state):\n",
    "        '''\n",
    "        Statistical method. 1# to provide instances for RL. 2# RL may not be a good approach for this problem.\n",
    "        '''\n",
    "        state = state[0:27]\n",
    "\n",
    "        # find length\n",
    "        l = len(self.env.curr_word)\n",
    "\n",
    "        dictionary = word_count_dict[l] #n-dictionary created outside the function.\n",
    "        pattern = ''\n",
    "    \n",
    "        for logit in state:\n",
    "            if logit == 26:\n",
    "                pattern += '.'\n",
    "            elif logit == -1:\n",
    "                pass\n",
    "            else:\n",
    "                pattern += chr(logit+ord('a'))\n",
    "\n",
    "    \n",
    "        selected_dictionary = []\n",
    "        for wrd in dictionary:\n",
    "    \n",
    "            # match pattern\n",
    "            if re.match(pattern,wrd):\n",
    "                selected_dictionary.append(wrd)\n",
    "        \n",
    "\n",
    "        # use this to update the n-grams\n",
    "        guessed = [chr(idx + ord('a')) for idx in range(26) if self.env.guessed_letters[idx] == 1]\n",
    "        correct = self.correct_letter(state)\n",
    "        wrong = list(set(guessed)-set(correct))\n",
    "\n",
    "        vowel_idx = [0,4,8,14,20]\n",
    "        vowel_count = sum([1 if state[idx] in [0,4,8,14,20] else 0 for idx in range(27)])\n",
    "        guess_vowel = vowel_count < 0.55 #test against 0.5 and 0.45\n",
    "\n",
    "        \n",
    "        N_gram = n_gram(selected_dictionary)\n",
    "        \n",
    "        unigram = N_gram.unigram.most_common()\n",
    "      \n",
    "\n",
    "        \n",
    "        action = -1 #nothing is done if action = -1\n",
    "        \n",
    "        # return most frequently letter in possible selection of words\n",
    "        for letter, freq in unigram:\n",
    "            if letter not in guessed:\n",
    "                code = ord(letter)-ord('a')\n",
    "                if code in vowel_idx and not guess_vowel: \n",
    "                    action = code\n",
    "                    continue\n",
    "                action = code\n",
    "                break\n",
    "        \n",
    "        \n",
    "        if action  == -1: #l gram\n",
    "       \n",
    "            substring_dict = self.sub_dictionary(word_list, pattern)\n",
    "            l_gram = n_gram(substring_dict) \n",
    "            l_unigram = l_gram.unigram.most_common()\n",
    "       \n",
    "            for letter, freq in l_unigram:\n",
    "                if letter not in guessed:\n",
    "                    code = ord(letter)-ord('a')\n",
    "                    if code in vowel_idx and not guess_vowel:\n",
    "                        action = code\n",
    "                        continue\n",
    "                    action = code\n",
    "                    break\n",
    "\n",
    "        \n",
    "        # Shorter substring.....\n",
    "        if action  == -1:\n",
    "       \n",
    "            k = 5\n",
    "\n",
    "            subsubstring_dict = []\n",
    "            for idx in range(l-k+1):\n",
    "                subpattern = pattern[idx:idx+k]\n",
    "                subsubstring_dict += self.sub_dictionary(word_list, subpattern)\n",
    "                \n",
    "            l_gram = n_gram(subsubstring_dict) \n",
    "            l_unigram = l_gram.unigram.most_common()\n",
    "        \n",
    "            for letter, freq in l_unigram:\n",
    "                if letter not in guessed:\n",
    "                    code = ord(letter)-ord('a')\n",
    "                    if code in vowel_idx and not guess_vowel:\n",
    "                        action = code\n",
    "                        continue\n",
    "                    action = code\n",
    "                    break\n",
    "                    \n",
    "        if action  == -1:\n",
    "            k = 3\n",
    "        \n",
    "            subsubstring_dict = []\n",
    "            for idx in range(l-k+1):\n",
    "                subpattern = pattern[idx:idx+k]\n",
    "                subsubstring_dict += self.sub_dictionary(word_list, subpattern)\n",
    "\n",
    "            l_gram = n_gram(subsubstring_dict) \n",
    "            l_unigram = l_gram.unigram.most_common()\n",
    "            for letter, freq in l_unigram.items():\n",
    "                if letter not in guessed:\n",
    "                    code = ord(letter)-ord('a')\n",
    "                    if code in vowel_idx and not guess_vowel:\n",
    "                        action = code\n",
    "                        continue\n",
    "                    action = code\n",
    "                    break\n",
    "\n",
    "        \n",
    "        if action == -1:\n",
    "            n_gram_act = n_gram(word_list)\n",
    "            probability = n_gram_act.ngram_probability(state, weight = [1,0,0,0,0])\n",
    "            sorted_act = np.argpartition(probability, -26)[-26:]\n",
    "               \n",
    "                #largest_k_elements = arr[largest_k_indices]\n",
    "            for act in sorted_act:\n",
    "                if chr(act+ord('a')) not in guessed:\n",
    "                    action = act\n",
    "                    \n",
    "        return action\n",
    "        \n",
    "\n",
    "    def act(self, state, for_test = False):\n",
    "        '''\n",
    "        Select an action. This is the function to call when playing the game.\n",
    "        '''\n",
    "       \n",
    "        sample = rnd.random()\n",
    "        eps = self.eps_scheduler()*0\n",
    "        if for_test:\n",
    "            eps = 0.45\n",
    "        self.step_count += 1\n",
    "        countobs = sum([1 if k==26 else 0 for k in state])\n",
    "        guess_vowel = self.do_vowel(state[0:27])\n",
    "\n",
    "        vowel_idx = [0,4,8,14,20]\n",
    "        vowel = sum([1 if self.env.guessed_letters[idx]== 1 else 0 for idx in [0,4,8,14,20] ])\n",
    "\n",
    "\n",
    "        action = -1    \n",
    "        if sample > eps: #exploit\n",
    "            with torch.no_grad():\n",
    "                action_sequence = self.policy_net(state.float())\n",
    "                #selected_action = self.policy_net(state.float()).argmax() # what if I change it to select the max unguessed letter?? --08/27\n",
    "                _, actions = torch.topk(action_sequence, 8, sorted = False)\n",
    "                \n",
    "                for action_idx in actions.squeeze().tolist():\n",
    "                    if self.env.guessed_letters[action_idx] == 0:\n",
    "                        if guess_vowel:\n",
    "                            action = action_idx\n",
    "                        else:\n",
    "                            if action_idx not in [0,4,8,14,20]:\n",
    "                                action = action_idx\n",
    "                    else:\n",
    "                        selected_action = self.heuristic_action(state) # set to random guess\n",
    "                        action = selected_action\n",
    "                        \n",
    "\n",
    "        elif  eps*1/2 < sample < eps:\n",
    "          \n",
    "            selected_action = self.act_stat(state[0:27])\n",
    "                \n",
    "            action = selected_action\n",
    "\n",
    "        \n",
    "        else: #explore, using heuristic\n",
    "   \n",
    "            \n",
    "            selected_action = self.heuristic_action(state) # set to random guess\n",
    " \n",
    "            action = selected_action\n",
    "\n",
    "        return action\n",
    "        \n",
    "\n",
    "\n",
    "    def train_n_play(self):\n",
    "        '''\n",
    "        The training loop\n",
    "        '''\n",
    "        \n",
    "        #self.observation_space = Tuple((\n",
    "\t\t#\tMultiDiscrete(np.array([MaxLen]*27)),  # The state space of strings \n",
    "\t\t#\tMultiBinary(26),                            # Guessed letters 0 or 1\n",
    "        #    Discrete(6 + 1) # attempt left = 0-6\n",
    "        #    )) \n",
    "        num_episodes = self.config.num_episodes\n",
    "        self.episode_durations = []\n",
    "        self.reward_in_episode = []\n",
    "        reward_in_episode = 0\n",
    "        for epi_idx in range(num_episodes):\n",
    "            # episode start. Initiate env.\n",
    "            state = self.env.reset()\n",
    "           \n",
    "            \n",
    "            state = torch.cat((state[0], state[1], torch.tensor(state[2]).unsqueeze(0)), dim=0)\n",
    "          \n",
    "            count = -1\n",
    "            while True:\n",
    "                count += 1\n",
    "                \n",
    "                action = self.act_stat2(state)\n",
    "          \n",
    "                next_state, reward, done, _ = self.env.step(int(action))\n",
    "         \n",
    "                next_state = torch.cat((next_state[0], next_state[1],torch.tensor(next_state[2]).unsqueeze(0)), dim=0)\n",
    "\n",
    "                # Store the transition\n",
    "                self.memory.push(state, action, next_state, reward)\n",
    "                \n",
    "                if epi_idx >= self.config.warmup: \n",
    "                    self.replay()\n",
    "                    self.scheduler.step()\n",
    "                    done = (count > 28) or done\n",
    "                else:\n",
    "                    done = (count > 28) or done\n",
    "                \n",
    "                    \n",
    "\n",
    "                \n",
    "                # Move to the next state\n",
    "                state = next_state\n",
    "                reward_in_episode += reward\n",
    "\n",
    "                if epi_idx % 1 == 0:\n",
    "                    print('episode', epi_idx)\n",
    "                    self.env.render()\n",
    "                    print(self.eps_scheduler())\n",
    "                \n",
    "                \n",
    "\n",
    "                if done:\n",
    "                    self.episode_durations.append(count + 1)\n",
    "                    self.reward_in_episode.append(reward_in_episode)\n",
    "                    reward_in_episode = 0\n",
    "                    break\n",
    "\n",
    "\n",
    "                self.last_episode = epi_idx\n",
    "\n",
    "                if done:\n",
    "                    self.episode_durations.append(count + 1)\n",
    "\n",
    "                    break\n",
    "                \n",
    "            # Update the target network\n",
    "            if epi_idx % 100 == 0:\n",
    "                self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "               \n",
    "         \n",
    "            if epi_idx % 100 == 0:\n",
    "                self.save(self.config.save_file_name)\n",
    "    \n",
    "\n",
    "    def sub_dictionary(self, full_dict, word_pattern):\n",
    "        '''\n",
    "        create a subdictionary for high-quality prediction.\n",
    "        '''\n",
    "        \n",
    "        full_dict\n",
    "        new_dictionary = []\n",
    "        l = len(word_pattern)\n",
    "        for dict_word in full_dict:\n",
    "            for i in range(len(dict_word)-l):\n",
    "                if re.match(word_pattern,dict_word[i:i+l]):\n",
    "                    new_dictionary.append(dict_word[i:i+l])\n",
    "        return new_dictionary\n",
    "\n",
    "    \n",
    "    def replay(self):\n",
    "        \"\"\"\n",
    "        essentially,\n",
    "        the training loop\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = self.config.batch_size\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        transitions = self.memory.sample(batch_size)\n",
    "\n",
    "        # to Transition of batch-arrays.\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        \n",
    "        \n",
    "        non_empty_indicator = torch.tensor([1 if s is not None else 0 for s in batch.next_state], device=self.device, dtype=torch.bool)\n",
    "        \n",
    "        cat_next_states = torch.cat([s.clone().detach() for s in batch.next_state if s is not None])\n",
    "        \n",
    "        # collate\n",
    "        cat_state = torch.cat(batch.state)\n",
    "   \n",
    "        cat_action  = torch.tensor(batch.action)\n",
    "\n",
    "    \n",
    "        cat_reward = torch.tensor(batch.reward)\n",
    "        cat_state.resize_(batch_size, 27+26+1).to(self.device).float().requires_grad_(True)\n",
    "        cat_next_states.resize_(batch_size, 27+26+1).to(self.device).float().requires_grad_(True)\n",
    "        \n",
    "        # compute Q from policy_net\n",
    "        curr_state_Q = self.policy_net(cat_state.float()).squeeze()[torch.arange(batch_size), cat_action] # 0827 the problem is this line.\n",
    "\n",
    "        \n",
    "        next_state_Q = torch.zeros(batch_size, device=self.device, dtype=torch.float)\n",
    "\n",
    "        next_state_Q[non_empty_indicator] = self.target_net(cat_next_states.float()).squeeze().max(1)[0].detach()\n",
    "\n",
    "        expected_curr_state_Q = (next_state_Q * self.config.gamma) + cat_reward\n",
    "\n",
    "        # Try to switch betwwen Huber loss and MSE??\n",
    "        if self.config.lossfn == 'huber':\n",
    "            criterion = nn.SmoothL1Loss()\n",
    "            loss = criterion(curr_state_Q, expected_curr_state_Q).float()\n",
    "\n",
    "        if self.config.lossfn == 'mse':\n",
    "            criterion = nn.MSELoss()\n",
    "            loss = criterion(curr_state_Q, expected_curr_state_Q).float()\n",
    "            \n",
    "    \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "   \n",
    "        for name, param in self.policy_net.named_parameters():\n",
    " \n",
    "            param.grad.data.clamp_(-1.1, 1.1)\n",
    "  \n",
    "        self.optimizer.step()\n",
    "    \n",
    "    def save(self, filename):\n",
    "        torch.save({\n",
    "            'policy': self.policy_net.state_dict(),\n",
    "            'target': self.target_net.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            \"reward\": self.reward_in_episode,\n",
    "            \"episode_durations\": self.episode_durations,\n",
    "            \"config\": self.config\n",
    "            }, filename)\n",
    "        \n",
    "    def load(self, filename = 'train_01.pth'):\n",
    "        checkpoint = torch.load(filename)\n",
    "        self.policy_net.load_state_dict(checkpoint['policy'])\n",
    "        self.target_net.load_state_dict(checkpoint['target'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        self.reward_in_episode = checkpoint['reward']\n",
    "        self.episode_durations = checkpoint['episode_durations']\n",
    "        self.config = checkpoint['config']\n",
    "\n",
    "   \n",
    "\n",
    "   \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first trained this askdjhg!@(*&asd with the 'word_250000_train_txt' \n",
    "train_instance = agent_hangman()\n",
    "train_instance.load(filename = \"train_160000.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0\n",
      "Word: _ _ _ _ _\n",
      "Guessed Letters: e\n",
      "Attempts Left: 5\n",
      "1.0\n",
      "episode 0\n",
      "Word: _ _ _ _ _\n",
      "Guessed Letters: e, i\n",
      "Attempts Left: 4\n",
      "1.0\n",
      "episode 0\n",
      "Word: _ _ _ _ _\n",
      "Guessed Letters: a, e, i\n",
      "Attempts Left: 3\n",
      "1.0\n",
      "episode 0\n",
      "Word: _ o _ _ _\n",
      "Guessed Letters: a, e, i, o\n",
      "Attempts Left: 3\n",
      "1.0\n",
      "episode 0\n",
      "Word: _ o _ _ _\n",
      "Guessed Letters: a, e, i, n, o\n",
      "Attempts Left: 2\n",
      "1.0\n",
      "episode 0\n",
      "Word: _ o _ _ _\n",
      "Guessed Letters: a, e, i, n, o, r\n",
      "Attempts Left: 1\n",
      "1.0\n",
      "episode 0\n",
      "Word: _ o _ _ _\n",
      "Guessed Letters: a, e, i, n, o, r, t\n",
      "Attempts Left: 0\n",
      "1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[209], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_n_play\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[205], line 433\u001b[0m, in \u001b[0;36magent_hangman.train_n_play\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    431\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 433\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_stat2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28mint\u001b[39m(action))\n\u001b[0;32m    437\u001b[0m     next_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((next_state[\u001b[38;5;241m0\u001b[39m], next_state[\u001b[38;5;241m1\u001b[39m],torch\u001b[38;5;241m.\u001b[39mtensor(next_state[\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[205], line 286\u001b[0m, in \u001b[0;36magent_hangman.act_stat2\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action  \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m: \u001b[38;5;66;03m#l gram\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     substring_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msub_dictionary(word_list, pattern)\n\u001b[1;32m--> 286\u001b[0m     l_gram \u001b[38;5;241m=\u001b[39m \u001b[43mn_gram\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubstring_dict\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m    287\u001b[0m     l_unigram \u001b[38;5;241m=\u001b[39m l_gram\u001b[38;5;241m.\u001b[39munigram\u001b[38;5;241m.\u001b[39mmost_common()\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m letter, freq \u001b[38;5;129;01min\u001b[39;00m l_unigram:\n",
      "Cell \u001b[1;32mIn[177], line 21\u001b[0m, in \u001b[0;36mn_gram.__init__\u001b[1;34m(self, dictionary, list_to_exclude, trimlength)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_dict \u001b[38;5;241m=\u001b[39m dictionary \u001b[38;5;66;03m#give me a list\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdict_clean_up(list_to_exclude)\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_grams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[177], line 41\u001b[0m, in \u001b[0;36mn_gram.make_grams\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_grams\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munigram \u001b[38;5;241m=\u001b[39m \u001b[43mcount_ngrams\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbigram \u001b[38;5;241m=\u001b[39m count_ngrams(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_dict, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigram \u001b[38;5;241m=\u001b[39m count_ngrams(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_dict, \u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[1;32mIn[171], line 11\u001b[0m, in \u001b[0;36mcount_ngrams\u001b[1;34m(wordlist, n)\u001b[0m\n\u001b[0;32m      9\u001b[0m     ngrams \u001b[38;5;241m=\u001b[39m letter_ngrams(word, n)\n\u001b[0;32m     10\u001b[0m     all_ngrams\u001b[38;5;241m.\u001b[39mextend(ngrams)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCounter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_ngrams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\collections\\__init__.py:593\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;124;03mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;124;03mof elements to their counts.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    590\u001b[0m \n\u001b[0;32m    591\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 593\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(iterable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\collections\\__init__.py:680\u001b[0m, in \u001b[0;36mCounter.update\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m         _count_elements(\u001b[38;5;28mself\u001b[39m, iterable)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds:\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_instance.train_n_play()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions for using the API and my game env\n",
    "\n",
    "def to_guessed_letter(letterlist):\n",
    "    ''' change self.guessed_letters\n",
    "    '''\n",
    "    ls = [0 for i in range(26)]\n",
    "    for l in letterlist:\n",
    "        ls[ord(l)-ord('a')] = 1\n",
    "    return ls\n",
    "\n",
    "\n",
    "def to_state(word):\n",
    "    ls = [-1 for i in range(max(len(word),27))] \n",
    "    idx = 0\n",
    "    for k in word:\n",
    "        if k not in 'abcdefghijklmnopqrstuvwxyz':\n",
    "            ls[idx] = 26\n",
    "        else:\n",
    "            ls[idx] = ord(k)-ord('a')\n",
    "        idx += 1\n",
    "    #shape torch.size([])\n",
    "    return ls[0:27]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "filename = 'test_instances' + '.csv'\n",
    "with open(filename, 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
